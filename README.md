# What strategies might lead us to successful Global AI Governance?

Artificial intelligence (AI) has the potential to radically change the society we live in. AI-enabled technologies are already widely used in financial trading, in legal and medical domains, advertising, law enforcement and the military. Recent progress has been fast, leading many experts to believe that an Artificial General Intelligence (AGI) with human-like or super-human intelligence is achievable in the near to mid-term future. While AGI holds the promise of solving many of humanities most-pressing problems it likely will be hard to control and to align with human interests. One way to mitigate this danger is to establish a functioning International AI Governance regime that would implement and enforce worldwide AI standards and prevent that an international race for dominance in AI compromises safety. However, coordinating many independent countries to agree on common guidelines is no small task and the history of Global Governance has seen many failures. In the following I will outline common problems of Global Governance and how they might be overcome: 
## Shortcomings of International Global Governance
The UN and many other intergovernmental organizations are infamously inefficient. These structures allow countries to discuss common initiatives, but it is not uncommon that a misplaced comma in a draft text put negotiations on hold, as representatives need further guidance from their governments. Global international norms and policies develop very slowly. Urgency emerges when crisis is inevitable or has already occurred. Even then, the result is not guaranteed. For example, the genocide in Ruanda was not averted, the climate is changing but the major CO2 polluter is leaving the Paris Agreement, and poisonous gases were widely used in WWI, despite the fact that the Hague Convention outlawed the use of chemical agents. Only the horrific scale of gas use in WWI finally lead to the creation of Geneva Protocol that further prohibited and reinforced the ban. Even non-binding agreements (which only recommend but do not require legal actions by governments) such as the recent UN migration pact often run into fierce resistance by countries. In addition, global policy making is heavily influence by geopolitical interests and is often interpreted as a zero-sum game. In a geopolitical environment technology becomes a tool to achieve dominance over other nations. If AI governance is similarly interpreted as a zero-sum game, society will be at risk. A particular challenge for AI governance is that, unlike global governance institutions, the tech community creates and commercializes innovations at a pace that is unimaginable for most governmental bureaucracies around the world. How can this slow-moving machine of international and national bureaucracies control the potential risks of AI while still allowing society to profit from its benefits?
## AI Advocacy and Smaller States 
The USA and China are two countries that are commonly believed to lead the world in AI development and are often referred to as AI Superpowers. Unfortunately, the relationship between the two has been deteriorating with Chinese technology more and more seen as a threat to US security. For example, a report by President Obama’s Council of Advisors on Science and Technology underscored the importance of the microelectronics industry for national security and suggested to “push back against innovation-inhibiting Chinese industrial policy”.  The Trump administration took the escalation a step further, pressuring allied governments to prevent Chinese manufacturer Huawei from deploying and controlling the new high-speed wireless 5G infrastructure in their countries. The Huawei case demonstrates how both countries relentlessly strive for strategic advantages in key technologies. The race over AI dominance will likely be more aggressive. 

If China and the USA are focused on protecting perceived advantages in AI technology, the danger is that geopolitical interest will prevail over AI safety. In addition, due to their role as AI Superpowers, an international AI governance effort by either China or the USA is less likely to succeed: First, any such effort would be subjected to substantial domestic pressures to shape governance rules in the interest of dominance. And second, even if the international governance proposal would be able to withstand such forces, the governments and the public of third countries might still suspect ulterior motives. For these reasons, many successful examples of international policy incentives come from smaller countries. Smaller countries are more often perceived as impartial rather than seen as a threat. In turn, they can gain political credits by leading incentives on the international arena. Norway, for example, has led many successful negotiations and incentives: It led the Oslo Accords between Israel and the Palestine Liberation Organization, the so-called Nansen initiative, a state-led, bottom-up consultative process that helped to build a consensus on the status of people displaced across borders by natural disasters and climate change (another example of a politicized topic) and the Oslo Process, an international negotiation process that led to the convention banning the use and production of cluster munitions. The convention is one of the international disarmament success stories. 
## TechPlomacy: Combining technical knowledge of AI advocates with diplomatic expertise of impartial countries
The Danish government has made recent efforts to impact international tech policy. Since 2017, Denmark is pioneering an initiative called TechPlomacy that aims to provides a formal diplomatic platform under the ministry of Foreign Affairs to engage in multi-stakeholder discussions with the aim to define the future of public policy and global governance of technologies. As part of the initiative, Denmark created Tech Embassies in Silicon Valley and Beijing. This initiative demonstrates that Denmark would like to play an important role in technology governance and can become an important partner of tech companies and organizations working on the safe use of AI. Combining technical knowledge of AI advocates with diplomatic expertise of impartial countries can accelerate the adoption of an international AI policy that is ethical and focused on safety.

Nordic countries might be well equipped to jump-start the process towards international AI Governance. In 2018, the Nordic Council, an intergovernmental organization that includes Denmark, Finland, Iceland, Norway and Sweden as its member states, adopted a declaration to promote digital leadership in the Nordic-Baltic region and support “ethical and transparent guidelines, standards, principles and values to guide when and how AI applications should be used”. 

Canada is invested in establishing itself as a global AI hub. It is already home to leading AI research organizations and is developing an entrepreneurial AI ecosystem. However, its current involvement in the Huawei case affected its relationship with China, which might weaken its position as a global policy maker. Under President Macron, France publicly declared its ambition to establish itself as an AI center. France played a crucial role in reaching an international consensus on the Paris Climate agreement, a policy-making experience that can be transferred to AI. In fact, France and Canada joined their forces and announced the establishment of the International Panel on Artificial Intelligence (IPAI) that will be based after the Intergovernmental Panel on Climate Change (IPCC) and will publish reports. IPAI is an incentive of G7 countries but will be open to all UN member states. The goal of the panel is to guide responsible policy development and the adoption of AI that is “human-centric and grounded in respect for human rights, inclusion, diversity, innovation and economic growth”. In the case of Climate Change, the IPCC has proven to be an important instrument to establish a scientific consensus on which policy-making can be based, but it remains to be seen whether a similar structure is flexible enough for a fast-moving field as AI technology.
## National Level Policy Making and Bottom-up AI Governance and Decentralization.
A promising model for the implementation of AI policy could be the “bottom-up” (also called inductive) global governance model: In this model, advocates for safe AI would simultaneously engage with national AI policy building around the world. Already now, countries around the world are rapidly developing domestic AI strategies. AI advocates would engage with individual countries to make sure that domestic AI strategies are technically informed and include provisions for AI safety and ethics. One of the reasons that the Paris agreement was successful is that the majority of countries present at the summit filed national plans for reducing CO2 emissions beforehand. This model also requires the engagement of non-state actors such as non-profit organizations to inform both governments and the public and to help aligning national AI policies of different countries. The bottom-up approach enabled the creation of the US Climate Alliance that brings together states and cities around the US who want to commit to the principals of Paris Climate Deal in spite of President Trump leaving the agreement. Hence, even if a policy initiative fails at the international level, the bottom-up governance approach can safeguard its provision on a local level. In addition, the Paris agreement is an example of decentralization, as it did not introduce legally binding CO2 emission reduction targets, but allowed states to decide on their actions, as long as they can keep the global temperature increase under 1.5C. This flexibility greatly facilitated the deal. 
## What should be the focus of International AI Policy?
To provide a stable foundation for an International AI Policy, it is important to find a formulation of goals that are more likely to lead to the creation of universally accepted standards across countries. For example, Canada and France emphasized that the IPAI should work on AI policy that is “human-centric and grounded in respect for human rights”. While the impact of AI technologies on human rights such as privacy and freedom of speech is certainly important, the term “human rights” is likely to alienate countries such as China which might perceive this initiative as targeted against them. A politically formulated agenda might encourage the perception of a zero-sum game and drive less democratic countries to collaborate outside of an official AI platform, and therefore expose the world to the risk of unsafe AI technologies. Focusing instead on AI safety and universal ethical standards might encourage cooperation, paving a faster way towards international safety standards. 

In addition, governments are more likely to engage in AI policy efforts if the process can address their immediate concerns about the impact of the deployment of AI technologies on their societies and help them form domestic policies. Besides AI safety of future technologies, countries might need guidance on which current AI technologies can already be safely integrated in their economies and societies, how regulations should deal with technical problems such as a lack of AI interpretability, AI-generated biases, adversarial attacks, issues of data privacy, the prevention of AI-powered trolls that bias and influence political discussions and undermine democracy, and the short and midterm impact of AI-powered automation on employment. Incorporating a consultation process in an AI governance framework might provide a strong incentive for countries to join and openly share their concerns.
